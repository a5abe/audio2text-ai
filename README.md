# ğŸ¹ audio2text-ai

## ğŸ§  Motivation

**An experiment: "Letting ChatGPT (which has no ears) listen to my piano performance."**

As a hobby pianist, I often record short sessions of improvised or meditative playing.  
This time, I wanted to share those musical moments with ChatGPT and my internal thought framework â€” a multi-voice dialogue system I call "Asabe Brain Symposium."

The question was:  
**"How can I let an AI *understand* my music without hearing it?"**

## ğŸ› ï¸ What this project does

- Converts `.m4a` audio into `.wav` using `ffmpeg`  
- Uses `librosa` to extract pitch and visualize it over time  
- Generates a frequency vs. time graph to represent the music  
- (Planned) Translate pitch features into a human-readable musical story

## ğŸ“¦ Requirements

Set up with `uv`:

```bash
uv venv
uv pip install numpy scipy matplotlib librosa
````

Or install with regular `pip`.

## â–¶ï¸ How to run

```bash
uv run :main.py
```

Youâ€™ll need:

* `input.m4a` (audio file)
* `ffmpeg` installed

## ğŸ’» Environment

* OS: Windows 10
* Python: 3.11
* Tool: [uv](https://github.com/astral-sh/uv) for lightweight environment management
* Audio tools: ffmpeg

## ğŸ™ Final words

If you're curious about AI, music, or how to make machines "feel" human intention â€” welcome aboard.
This is just a first step. Let's keep experimenting.

---

## ğŸ¹ audio2text-aiï¼ˆæ—¥æœ¬èªï¼‰

## ğŸ§  å‹•æ©Ÿ

**è€³ã®ãªã„ChatGPTã«ã€è‡ªåˆ†ã®ãƒ”ã‚¢ãƒæ¼”å¥ã‚’â€œè´ã‹ã›ã¦ã¿ã‚‹â€å®Ÿé¨“ã€‚**

è¶£å‘³ã§ãƒ”ã‚¢ãƒã‚’å¼¾ã„ã¦ã„ã¦ã€ç‘æƒ³çš„ã«éŸ³ã‚’å‡ºã—ã¦éŒ²éŸ³ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ä»Šå›ã¯ãã‚Œã‚’ã€ã€Œè€³ã®ãªã„ChatGPTã€ã¨ã€Œè‡ªåˆ†ã®é ­ã®ä¸­ã«ã‚ã‚‹å¤šå£°çš„ãªæ€è€ƒãƒ¡ãƒ³ãƒãƒ¼ãŸã¡ï¼ˆã‚ã•ã¹è„³ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ï¼‰ã€ã«è´ã‹ã›ãŸã„ã¨æ€ã„ã¾ã—ãŸã€‚

å•ã„ã¯ã“ã†ã§ã™ï¼š
**ã€ŒAIã«ã€éŸ³ã‚’â€œè´ã‹ãšã«â€éŸ³æ¥½ã‚’å±Šã‘ã‚‹ã«ã¯ã©ã†ã—ãŸã‚‰ã„ã„ï¼Ÿã€**

## ğŸ› ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…å®¹

* `ffmpeg`ã§ `.m4a` ã‚’ `.wav` ã«å¤‰æ›
* `librosa`ã§éŸ³ã®ãƒ”ãƒƒãƒã‚’åˆ†æã—ã€æ™‚é–“è»¸ã§å¯è¦–åŒ–
* ã€ŒéŸ³æ¥½ã£ã½ã•ã€ã‚’ãƒ—ãƒ­ãƒƒãƒˆã§è¡¨ç¾
* ï¼ˆä»Šå¾Œï¼‰ChatGPTã¨èªã‚Œã‚‹ã‚ˆã†ãªâ€œéŸ³ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼â€ã«å¤‰æ›ã—ãŸã„

## ğŸ“¦ å¿…è¦ç’°å¢ƒ

`uv` ã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹å ´åˆï¼š

```bash
uv venv
uv pip install numpy scipy matplotlib librosa
```

`pip` ã§ã‚‚OKã€‚

## â–¶ï¸ å®Ÿè¡Œæ–¹æ³•

```bash
uv run :main.py
```

äº‹å‰ã«å¿…è¦ãªã®ã¯ï¼š

* `input.m4a`ï¼ˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
* `ffmpeg` ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

## ğŸ’» å‹•ä½œç’°å¢ƒï¼ˆå‚è€ƒï¼‰

* OS: Windows 10
* Python: 3.11
* ç’°å¢ƒç®¡ç†ãƒ„ãƒ¼ãƒ«: [uv](https://github.com/astral-sh/uv)
* éŸ³å£°å‡¦ç†: ffmpeg

## ğŸ™ æœ€å¾Œã«

AIã‚„éŸ³æ¥½ã€äººé–“ã®æ€ã„ã‚’â€œæ©Ÿæ¢°ã«æ„Ÿã˜ã•ã›ã‚‹â€æ–¹æ³•ã«èˆˆå‘³ãŒã‚ã‚‹ãªã‚‰ã€ãœã²ã‚ˆã†ã“ãã€‚
ã“ã‚Œã¯ã¾ã ç¬¬ä¸€æ­©ã€‚ã“ã‚Œã‹ã‚‰ã‚‚éŠã‚“ã§ã„ã“ã†ã€‚